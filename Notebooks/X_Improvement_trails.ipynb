{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = pd.read_csv('processed data/X.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improvement to preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sentiment",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "38acaa3c-4b21-4ba7-97e6-eaf8e62753fc",
       "rows": [
        [
         "0",
         "@chrishasboobs AHHH I HOPE YOUR OK!!! ",
         "negative"
        ],
        [
         "1",
         "@misstoriblack cool , i have no tweet apps  for my razr 2",
         "negative"
        ],
        [
         "2",
         "@TiannaChaos i know  just family drama. its lame.hey next time u hang out with kim n u guys like have a sleepover or whatever, ill call u",
         "negative"
        ],
        [
         "3",
         "School email won't open  and I have geography stuff on there to revise! *Stupid School* :'(",
         "negative"
        ],
        [
         "4",
         "upper airways problem ",
         "negative"
        ],
        [
         "5",
         "Going to miss Pastor's sermon on Faith... ",
         "negative"
        ],
        [
         "6",
         "on lunch....dj should come eat with me ",
         "positive"
        ],
        [
         "7",
         "@piginthepoke oh why are you feeling like that? ",
         "negative"
        ],
        [
         "8",
         "gahh noo!peyton needs to live!this is horrible ",
         "negative"
        ],
        [
         "9",
         "@mrstessyman thank you glad you like it! There is a product review bit on the site  Enjoy knitting it!",
         "positive"
        ],
        [
         "10",
         "@PerezHilton Zach makes me pee sitting down! And I'm a grown gay man! ",
         "positive"
        ],
        [
         "11",
         "to sum up my day in one word ......... kackered! ",
         "positive"
        ],
        [
         "12",
         "@k9wkj Great minds think alike ",
         "positive"
        ],
        [
         "13",
         "Is Poorly and in bed! ",
         "negative"
        ],
        [
         "14",
         "@LilPecan Oh, that's really great  Here we have a small blizzard and also cold wind blows...",
         "positive"
        ],
        [
         "15",
         "@wizely lol, calm down.  i got a 30day loan offer for only 1500% ",
         "positive"
        ],
        [
         "16",
         "i'm feeling quite sleepy today, wish i could stay in bed today...but OK! is my LAST YEAR, so let's go to school ",
         "positive"
        ],
        [
         "17",
         "@nadalnews Yeah  Mathieu totally choked in the 3rd set to let Rog win as well. Djokovic played TERRIBLY.  ",
         "negative"
        ],
        [
         "18",
         "ugh, morning's off to a rough start ",
         "negative"
        ],
        [
         "19",
         "just bit my tongue ",
         "negative"
        ],
        [
         "20",
         "@frandrescher Apparently you dont have time for ur fans!!!!!!!!!! ",
         "negative"
        ],
        [
         "21",
         "Whaddup Whaddup Whaddup Whaddup Whaddup  I Got white girl swag from MY HEAD TO MY shOES Whaddup @yungla ",
         "positive"
        ],
        [
         "22",
         "@GogDog I'd be willing to pay $40-50 (thus covering the cost of the set) for one of them, but if you've got a counter offer I'll listen. ",
         "positive"
        ],
        [
         "23",
         "Working on photos from Hillsong's 1 year celebration!!! stay tuned   www.hillsong.co.za",
         "positive"
        ],
        [
         "24",
         "baby's chicken pox are soo bad on the face, I am afraid she might have scars ",
         "negative"
        ],
        [
         "25",
         "i don't feel good ",
         "negative"
        ],
        [
         "26",
         "@edadkins ha ha I want to see pictures from when you were a minister!!!  *boobie flahses*!!!! ",
         "positive"
        ],
        [
         "27",
         "This day will pass slowly.  All of these days will.  RAWR!!!!  ... ",
         "negative"
        ],
        [
         "28",
         "my car is poorly ",
         "negative"
        ],
        [
         "29",
         "im turning 18 one week from now  but i don't feel excited  i really don't know why i've seen my friends  they got excited  but on my part",
         "positive"
        ],
        [
         "30",
         "No woooooork tomorrrow&amp;tuesday ",
         "positive"
        ],
        [
         "31",
         "Flatmates are still in the bathroom! ARGGH!! ",
         "negative"
        ],
        [
         "32",
         "I'm having an allergic reaction to silver earings ",
         "negative"
        ],
        [
         "33",
         "@RocDoogie I am, I'll admit...  maybe I'll feel better tomorrow, yo! Down 4 studio time??",
         "negative"
        ],
        [
         "34",
         "@jasonhooha Going back to sleep is such a great idea, unfortunately I'm already at work notebook-less ",
         "negative"
        ],
        [
         "35",
         "what is with msn making me click the wrong people. garrrrr ",
         "negative"
        ],
        [
         "36",
         "Too full of fizz but not enough cider ",
         "negative"
        ],
        [
         "37",
         "How to Get Your Ex Back (worked for me  http://bit.ly/ec8qJ",
         "positive"
        ],
        [
         "38",
         "Time to sleep... Long day again tomorrow ",
         "negative"
        ],
        [
         "39",
         "Hahaha blakk is reckkkin it. :p throwwwwwed. ",
         "positive"
        ],
        [
         "40",
         "Cubs game today! My first ever ",
         "positive"
        ],
        [
         "41",
         "@SuzySpaatz ~ hi! sounds like you're feeling a bit better...that's great! you have a great day! ",
         "positive"
        ],
        [
         "42",
         "@foprof LOL.  Leave a kid on internet and the kid will do stupid things.",
         "positive"
        ],
        [
         "43",
         "eating cha with eric ",
         "positive"
        ],
        [
         "44",
         "@StarJonesEsq On a good note, we DID meet at Marty Richards RED BALL a few years ago, you were so sweet to me I'll never forget it ",
         "positive"
        ],
        [
         "45",
         "My hands are officially tied. I don't think I'll have time for anything anymore  This includes the California meet ",
         "negative"
        ],
        [
         "46",
         "@Konstantine I said &quot;scar,&quot; sweetie. ",
         "positive"
        ],
        [
         "47",
         "@CamilleJ it was supposed to go live on tv but it didn't happened in the end  that would have been cool being on the bbc...",
         "negative"
        ],
        [
         "48",
         "FCK-Brï¿½ndby 4-0! ",
         "positive"
        ],
        [
         "49",
         "@team_allen jealous!  I'm yet to find a local chinese i'm satisfied with ",
         "negative"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 400000
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@chrishasboobs AHHH I HOPE YOUR OK!!!</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@misstoriblack cool , i have no tweet apps  fo...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@TiannaChaos i know  just family drama. its la...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>School email won't open  and I have geography ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>upper airways problem</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399995</th>\n",
       "      <td>@brykins Splendid! I was told I looked like a ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399996</th>\n",
       "      <td>@herbadmother I'm so sorry!  that IS sad</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399997</th>\n",
       "      <td>@JosieStingray Sounds like Eddie Murphy is coo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399998</th>\n",
       "      <td>http://twitpic.com/4incl - The tiny Porter pla...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399999</th>\n",
       "      <td>Im glad i got my old gameboy to work,now whene...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "0                  @chrishasboobs AHHH I HOPE YOUR OK!!!   negative\n",
       "1       @misstoriblack cool , i have no tweet apps  fo...  negative\n",
       "2       @TiannaChaos i know  just family drama. its la...  negative\n",
       "3       School email won't open  and I have geography ...  negative\n",
       "4                                  upper airways problem   negative\n",
       "...                                                   ...       ...\n",
       "399995  @brykins Splendid! I was told I looked like a ...  negative\n",
       "399996          @herbadmother I'm so sorry!  that IS sad   negative\n",
       "399997  @JosieStingray Sounds like Eddie Murphy is coo...  positive\n",
       "399998  http://twitpic.com/4incl - The tiny Porter pla...  negative\n",
       "399999  Im glad i got my old gameboy to work,now whene...  positive\n",
       "\n",
       "[400000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import emoji\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from textblob import TextBlob\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textblob.download_corpora as download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABBREVIATIONS = {\n",
    "    \"u\": \"you\", \"r\": \"are\", \"ur\": \"your\", \"n\": \"and\", \"luv\": \"love\",\n",
    "    \"im\": \"I'm\", \"wanna\": \"want to\", \"gonna\": \"going to\", \"btw\": \"by the way\",\n",
    "    \"idk\": \"I don't know\", \"smh\": \"shaking my head\", \"lol\": \"laugh out loud\",\n",
    "    \"omg\": \"oh my god\", \"tbh\": \"to be honest\", \"brb\": \"be right back\",\n",
    "    \"lmao\": \"laughing my ass off\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ, \"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def correct_spelling(text):\n",
    "    words = text.split()\n",
    "    if len(words) <= 5:\n",
    "        return str(TextBlob(text).correct())\n",
    "    return text\n",
    "\n",
    "def preprocess_tweet(text):\n",
    "    if pd.isna(text):  \n",
    "        return []\n",
    "\n",
    "    text = emoji.demojize(text)\n",
    "    \n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
    "    \n",
    "    text = re.sub(r\"#(\\w+)\", r\"\\1\", text)\n",
    "    \n",
    "    words = text.split()\n",
    "    words = [ABBREVIATIONS.get(word, word) for word in words]\n",
    "    text = \" \".join(words)\n",
    "\n",
    "    text = correct_spelling(text)\n",
    "\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "\n",
    "    tokens = [\n",
    "        lemmatizer.lemmatize(word, get_wordnet_pos(word))\n",
    "        for word in tokens if word.isalpha() and word not in stop_words\n",
    "    ]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [1:19:06<00:00, 84.28it/s]  \n"
     ]
    }
   ],
   "source": [
    "df_X[\"tokenized_review\"] = df_X[\"review\"].progress_apply(preprocess_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amazon = pd.read_csv('processed data/amazon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sentiment",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "84723fcb-5e63-4cb5-bc54-d3ea80f0d029",
       "rows": [
        [
         "0",
         "great cd lovely pat one great voices generation listened cd years still love im good mood makes feel better bad mood evaporates like sugar rain cd oozes life vocals jusat stuunning lyrics kill one lifes hidden gems desert isle cd book never made big beyond everytime play matter black white young old male female everybody says one thing singing",
         "positive"
        ],
        [
         "1",
         "one best game music soundtracks game didnt really play despite fact played small portion game music heard plus connection chrono trigger great well led purchase soundtrack remains one favorite albums incredible mix fun epic emotional songs sad beautiful tracks especially like theres many kinds songs video game soundtracks must admit one songs lifea distant promise brought tears eyes many occasionsmy one complaint soundtrack use guitar fretting effects many songs find distracting even werent included would still consider collection worth",
         "positive"
        ],
        [
         "2",
         "batteries died within year bought charger jul worked ok design nice convenient however year batteries would hold charge might well get alkaline disposables look elsewhere charger comes batteries better staying power",
         "negative"
        ],
        [
         "3",
         "works fine maha energy better check maha energys website powerex mhcf charger works minutes rapid charge option slower charge better batteries mah batteries",
         "positive"
        ],
        [
         "4",
         "great nonaudiophile reviewed quite bit combo players hesitant due unfavorable reviews size machines weaning vhs collection dont want replace dvds unit well built easy setup resolution special effects progressive scan hdtv owners suitable many people looking versatile productcons universal remote",
         "positive"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>great cd lovely pat one great voices generatio...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>one best game music soundtracks game didnt rea...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>batteries died within year bought charger jul ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>works fine maha energy better check maha energ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great nonaudiophile reviewed quite bit combo p...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  great cd lovely pat one great voices generatio...  positive\n",
       "1  one best game music soundtracks game didnt rea...  positive\n",
       "2  batteries died within year bought charger jul ...  negative\n",
       "3  works fine maha energy better check maha energ...  positive\n",
       "4  great nonaudiophile reviewed quite bit combo p...  positive"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_amazon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "df_amazon = df_amazon.dropna(subset=[\"review\"])\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(df_amazon[\"review\"])\n",
    "\n",
    "joblib.dump(tfidf_vectorizer, \"tfidf_vectorizer.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fasttext_model.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "model_ft = FastText(sentences=df_amazon[\"review\"].apply(str.split), vector_size=300, window=10, min_count=5, workers=4)\n",
    "\n",
    "joblib.dump(model_ft, \"fasttext_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_vector(tokens):\n",
    "    return np.mean([model_ft.wv[word] for word in tokens if word in model_ft.wv] or [np.zeros(300)], axis=0)\n",
    "\n",
    "X_train_ft = np.vstack(df_amazon[\"review\"].apply(lambda x: get_sentence_vector(str(x).split())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_combined = hstack([X_train_tfidf, X_train_ft])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train_combined, df_amazon[\"sentiment\"].map({\"positive\": 1, \"negative\": 0}), test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-07 22:51:05,602] A new study created in memory with name: no-name-f2e7f445-82c1-4790-bb5c-ef018fc571f7\n",
      "[I 2025-03-07 22:56:22,976] Trial 2 finished with value: 0.8406 and parameters: {'n_estimators': 50, 'max_depth': 8, 'learning_rate': 0.11264082324782776, 'subsample': 0.7343986371114865, 'colsample_bytree': 0.66566162186621, 'gamma': 5.913858458647714, 'min_child_weight': 2}. Best is trial 2 with value: 0.8406.\n",
      "[I 2025-03-07 23:00:52,924] Trial 0 finished with value: 0.8109 and parameters: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.02699383083086185, 'subsample': 0.6970975399704095, 'colsample_bytree': 0.7146419801195466, 'gamma': 8.023962060852345, 'min_child_weight': 3}. Best is trial 2 with value: 0.8406.\n",
      "[I 2025-03-07 23:18:28,505] Trial 3 finished with value: 0.8558 and parameters: {'n_estimators': 350, 'max_depth': 4, 'learning_rate': 0.051278262523794686, 'subsample': 0.9409987492379168, 'colsample_bytree': 0.8085812121246679, 'gamma': 4.226159129700774, 'min_child_weight': 6}. Best is trial 3 with value: 0.8558.\n",
      "[I 2025-03-07 23:26:19,810] Trial 5 finished with value: 0.877 and parameters: {'n_estimators': 300, 'max_depth': 9, 'learning_rate': 0.07041379697716828, 'subsample': 0.9185484510264663, 'colsample_bytree': 0.6271482072028488, 'gamma': 8.78028595585457, 'min_child_weight': 3}. Best is trial 5 with value: 0.877.\n",
      "[I 2025-03-07 23:29:10,148] Trial 1 finished with value: 0.8704 and parameters: {'n_estimators': 400, 'max_depth': 9, 'learning_rate': 0.03783557983631123, 'subsample': 0.6861177550823231, 'colsample_bytree': 0.8516327781733706, 'gamma': 3.858383991416755, 'min_child_weight': 5}. Best is trial 5 with value: 0.877.\n",
      "[I 2025-03-07 23:30:44,580] Trial 4 finished with value: 0.883 and parameters: {'n_estimators': 450, 'max_depth': 4, 'learning_rate': 0.20154463338063022, 'subsample': 0.6600926179255865, 'colsample_bytree': 0.8762578152558655, 'gamma': 6.31043345881139, 'min_child_weight': 5}. Best is trial 4 with value: 0.883.\n",
      "[I 2025-03-07 23:41:59,749] Trial 9 finished with value: 0.8069 and parameters: {'n_estimators': 150, 'max_depth': 5, 'learning_rate': 0.02396292043983966, 'subsample': 0.8381005273072171, 'colsample_bytree': 0.6595364586236621, 'gamma': 1.2020046361054049, 'min_child_weight': 10}. Best is trial 4 with value: 0.883.\n",
      "[I 2025-03-07 23:44:00,139] Trial 8 finished with value: 0.8321 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.03268346201986967, 'subsample': 0.8805126478766895, 'colsample_bytree': 0.9574093710061402, 'gamma': 2.3817879564777575, 'min_child_weight': 2}. Best is trial 4 with value: 0.883.\n",
      "[I 2025-03-07 23:47:30,499] Trial 6 finished with value: 0.8852 and parameters: {'n_estimators': 450, 'max_depth': 8, 'learning_rate': 0.2469059744142288, 'subsample': 0.8900172778036246, 'colsample_bytree': 0.7135880444264231, 'gamma': 5.839036635890301, 'min_child_weight': 10}. Best is trial 6 with value: 0.8852.\n",
      "[I 2025-03-07 23:48:27,842] Trial 7 finished with value: 0.8301 and parameters: {'n_estimators': 400, 'max_depth': 5, 'learning_rate': 0.0161578048839909, 'subsample': 0.6795185849137495, 'colsample_bytree': 0.6939127994680738, 'gamma': 8.469002597098491, 'min_child_weight': 7}. Best is trial 6 with value: 0.8852.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳超参数: {'n_estimators': 450, 'max_depth': 8, 'learning_rate': 0.2469059744142288, 'subsample': 0.8900172778036246, 'colsample_bytree': 0.7135880444264231, 'gamma': 5.839036635890301, 'min_child_weight': 10}\n"
     ]
    }
   ],
   "source": [
    "# def objective(trial):\n",
    "#     params = {\n",
    "#         \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500, step=50),\n",
    "#         \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "#         \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "#         \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "#         \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "#         \"gamma\": trial.suggest_float(\"gamma\", 0, 10),\n",
    "#         \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "#         \"eval_metric\": \"logloss\"\n",
    "#     }\n",
    "    \n",
    "#     # 训练 XGBoost\n",
    "#     model = XGBClassifier(**params)\n",
    "#     model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
    "    \n",
    "#     # 预测测试集\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "#     return accuracy \n",
    "\n",
    "# study = optuna.create_study(direction=\"maximize\")\n",
    "# study.optimize(objective, n_trials=10, n_jobs=4) \n",
    "\n",
    "# best_params = study.best_params\n",
    "# print(\"最佳超参数:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF + FastText + XGBoost Performance on Amazon:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89     40007\n",
      "           1       0.89      0.89      0.89     39993\n",
      "\n",
      "    accuracy                           0.89     80000\n",
      "   macro avg       0.89      0.89      0.89     80000\n",
      "weighted avg       0.89      0.89      0.89     80000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['optimized_tfidf_fasttext_xgboost.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgb = XGBClassifier(\n",
    "    n_estimators=450,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.2469,\n",
    "    subsample=0.8900,\n",
    "    colsample_bytree=0.7136,\n",
    "    gamma=5.8390,\n",
    "    min_child_weight=10,\n",
    "    eval_metric=\"logloss\"\n",
    ")\n",
    "\n",
    "best_xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_best = best_xgb.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"TF-IDF + FastText + XGBoost Performance on Amazon:\")\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "\n",
    "joblib.dump(best_xgb, \"optimized_tfidf_fasttext_xgboost.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_tokenized = pd.read_csv('processed data/X_tokenized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sentiment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tokenized_review",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "db6a379e-1ab6-4775-b50d-eb6e0685a07a",
       "rows": [
        [
         "0",
         "Singstar nite last nite....my throat hurts ",
         "negative",
         "['singstar', 'nite', 'last', 'nite', 'throat', 'hurt']"
        ],
        [
         "1",
         "Up and ready for work  sad times mmm toast http://twitpic.com/4j8hc",
         "negative",
         "['ready', 'work', 'sad', 'time', 'mmm', 'toast']"
        ],
        [
         "2",
         "Watching another movie ",
         "positive",
         "['watch', 'another', 'movie']"
        ],
        [
         "3",
         "Listening to Ed Schultz interview of Mich. Gov. Granholm on GM Bankruptcy: Whoa! ",
         "negative",
         "['listen', 'ed', 'schultz', 'interview', 'mich', 'gov', 'granholm', 'gm', 'bankruptcy', 'whoa']"
        ],
        [
         "4",
         "@timothyh2o last time his bro was making up stories, it could be him again  but i'm not sure. Wat i'm sure of is that,that  is not jeff:/",
         "negative",
         "['last', 'time', 'bro', 'make', 'story', 'could', 'sure', 'wat', 'sure', 'jeff']"
        ],
        [
         "5",
         "I'm going to have new glass stuff in my shop today. The kiln was good to me. I just have to go get pictures ",
         "positive",
         "['go', 'new', 'glass', 'stuff', 'shop', 'today', 'kiln', 'good', 'go', 'get', 'picture']"
        ],
        [
         "6",
         "@ely_b awwww I miss my chocha ",
         "negative",
         "['miss', 'chocha']"
        ],
        [
         "7",
         "is sat watching ricki lake ",
         "positive",
         "['sat', 'watch', 'rich', 'lake']"
        ],
        [
         "8",
         "Packing to leave Miami ",
         "negative",
         "['pack', 'leave', 'diam']"
        ],
        [
         "9",
         "@redchinese19 yes  i dun wanna do no hard time man! Haha",
         "negative",
         "['yes', 'dun', 'want', 'hard', 'time', 'man', 'haha']"
        ],
        [
         "10",
         "I wonder how many took the time to get out their flag and fly it yesterday? I know not many in our area!   ",
         "negative",
         "['wonder', 'many', 'take', 'time', 'get', 'flag', 'fly', 'yesterday', 'know', 'many', 'area']"
        ],
        [
         "11",
         "I miss him too  higher standards jus don't want me though . .",
         "negative",
         "['miss', 'high', 'standard', 'jus', 'want', 'though']"
        ],
        [
         "12",
         "@LynettePatter You are the master of all today, my dear. Keep on giving us the power. ",
         "positive",
         "['master', 'today', 'dear', 'keep', 'give', 'u', 'power']"
        ],
        [
         "13",
         "@AngeLa_aA so far so good. hehe. how's school? uda transfer ke fidm kan? havin fun?! ",
         "positive",
         "['far', 'good', 'hehe', 'school', 'uda', 'transfer', 'ke', 'fidm', 'kan', 'havin', 'fun']"
        ],
        [
         "14",
         "@divide Lmao I just like google whoever and click on the images like most of the time. I'm terrible ",
         "negative",
         "['lmao', 'like', 'google', 'whoever', 'click', 'image', 'like', 'time', 'terrible']"
        ],
        [
         "15",
         "LADIES NIGHT!!!! Diner, ice cream and movies!!! And of course...GuuuRL TalK!! ",
         "positive",
         "['lady', 'night', 'diner', 'ice', 'cream', 'movie', 'course', 'guuurl', 'talk']"
        ],
        [
         "16",
         "@SciFiHeaven SO excited to hear about this movie. he should have more screen time in wolverine cuz he's awesome ",
         "positive",
         "['excite', 'hear', 'movie', 'screen', 'time', 'wolverine', 'cuz', 'awesome']"
        ],
        [
         "17",
         "Bummed that Grace is too sick for us to go to the Rocking Youth Service Planned for Tonight ",
         "negative",
         "['bum', 'grace', 'sick', 'u', 'go', 'rock', 'youth', 'service', 'plan', 'tonight']"
        ],
        [
         "18",
         "@elleNphilly my fellow Aquarian! ",
         "positive",
         "['fellow', 'aquarian']"
        ],
        [
         "19",
         "@jayemsee Yeah your probably right, I guess we'll have to wait and see ",
         "positive",
         "['yeah', 'probably', 'right', 'guess', 'wait', 'see']"
        ],
        [
         "20",
         "Steph, Zandy, Jeff and I just enjoyed our daily 3 gummy vitamins. Yummy. Unfortunately, vitamin time is over. ",
         "negative",
         "['steph', 'zandy', 'jeff', 'enjoy', 'daily', 'gummy', 'vitamin', 'yummy', 'unfortunately', 'vitamin', 'time']"
        ],
        [
         "21",
         "@missbeltran u down for boiling crab tonight??!!? ",
         "positive",
         "['boil', 'crab', 'tonight']"
        ],
        [
         "22",
         "Gonna eat. Again. ",
         "positive",
         "['donna', 'eat']"
        ],
        [
         "23",
         "@apestillrules it's meant to rain or something right? gutted! ",
         "negative",
         "['meant', 'rain', 'something', 'right', 'gutted']"
        ],
        [
         "24",
         "@russelltanner oooh @grazedotcom looks good!  How hearty are the boxes?  ",
         "positive",
         "['oooh', 'look', 'good', 'hearty', 'box']"
        ],
        [
         "25",
         "@girlgeeks Thanks for the retweet, much appreciated!!! ",
         "positive",
         "['thanks', 'retweet', 'much', 'appreciate']"
        ],
        [
         "26",
         "heath ledgers last film is supposed to be amazing i can't wait to see it ",
         "positive",
         "['heath', 'ledger', 'last', 'film', 'suppose', 'amaze', 'wait', 'see']"
        ],
        [
         "27",
         "@SwaggerReeLz  lol word the magic, i wasnt going for them tho i was goin for the CAVS  but i dont want the lakers to win so its magic now!",
         "negative",
         "['laugh', 'loud', 'word', 'magic', 'wasnt', 'go', 'tho', 'goin', 'cavs', 'dont', 'want', 'lakers', 'win', 'magic']"
        ],
        [
         "28",
         "@ItsK8TBitch its a teaser trailer for THIS IS IT! ",
         "positive",
         "['teaser', 'trailer']"
        ],
        [
         "29",
         "It takes a lot to stop me cooking. Toothache returns- grim!!! We will now eat take away from the local curry house ",
         "negative",
         "['take', 'lot', 'stop', 'cooking', 'toothache', 'return', 'grim', 'eat', 'take', 'away', 'local', 'curry', 'house']"
        ],
        [
         "30",
         "homeworkish, not ready for the upcoming week ",
         "negative",
         "['homeworkish', 'ready', 'upcoming', 'week']"
        ],
        [
         "31",
         "@arieeekim: yeah, i might hang out with Vero.. &amp; your saturday is boring because you're boring!  LOL, jk",
         "positive",
         "['yeah', 'might', 'hang', 'vero', 'saturday', 'boring', 'boring', 'lol', 'jk']"
        ],
        [
         "32",
         "@kcarruthers *flicks hair* I prefer to be called a &quot;twenius&quot; ",
         "positive",
         "['flick', 'hair', 'prefer', 'call', 'twenius']"
        ],
        [
         "33",
         "@alexd912 Ah man, I'm sorry to hear that  I was only just checking the pics on FB the other day too...",
         "negative",
         "['ah', 'man', 'sorry', 'hear', 'check', 'pic', 'fb', 'day']"
        ],
        [
         "34",
         "For anyone wondering about my cat, she went for my mum! She's a good cat really ",
         "positive",
         "['anyone', 'wonder', 'cat', 'go', 'mum', 'good', 'cat', 'really']"
        ],
        [
         "35",
         "@ronaldvalente what!  i was inspired by you to get one ",
         "positive",
         "['inspire', 'get', 'one']"
        ],
        [
         "36",
         "Had tea, made no difference,still can't sleep.Got to get up soon and not yet fallen asleep. This is not good ... ",
         "negative",
         "['tea', 'make', 'difference', 'still', 'get', 'soon', 'yet', 'fall', 'asleep', 'good']"
        ],
        [
         "37",
         "Turns out I am a 34 waist and a 36 arse! Fed up of trousers shopping now ",
         "negative",
         "['turn', 'waist', 'arse', 'fed', 'trouser', 'shopping']"
        ],
        [
         "38",
         "tummy ache ",
         "negative",
         "['mummy', 'ache']"
        ],
        [
         "39",
         "@French_Roast  give austin a farewell hug for me",
         "negative",
         "['give', 'austin', 'farewell', 'hug']"
        ],
        [
         "40",
         "off of twitter till later ",
         "positive",
         "['twitter', 'till', 'later']"
        ],
        [
         "41",
         "BR: monring tasks accomplished! sleepyyyyyyyyy  need a coffee",
         "negative",
         "['br', 'monring', 'task', 'accomplish', 'sleepyyy', 'need', 'coffee']"
        ],
        [
         "42",
         "just got back from a once in a life time opp times 3 ",
         "positive",
         "['get', 'back', 'life', 'time', 'opp', 'time']"
        ],
        [
         "43",
         "Checking out this Twitter stuff ",
         "positive",
         "['check', 'twitter', 'stuff']"
        ],
        [
         "44",
         "@DNK_Anais I feel reeeally bad now.... sorry ",
         "negative",
         "['feel', 'reeeally', 'bad', 'sorry']"
        ],
        [
         "45",
         "How to build a large MULTIMEDIA presentation online - from Soul of Athens 2009, LIVE TODAY!  http://bit.ly/1fBIk PLUS inspiring MM sites ",
         "positive",
         "['build', 'large', 'multimedia', 'presentation', 'online', 'soul', 'athens', 'live', 'today', 'plus', 'inspire', 'mm', 'site']"
        ],
        [
         "46",
         "@HelenCrozier Yes- It was fun to connect with her! Pls tell her hello- can't find her on Twitter. ",
         "negative",
         "['yes', 'fun', 'connect', 'pls', 'tell', 'hello', 'find', 'twitter']"
        ],
        [
         "47",
         "I've been working on a deck most of the day. And not the patio kind, sadly ",
         "negative",
         "['work', 'deck', 'day', 'patio', 'kind', 'sadly']"
        ],
        [
         "48",
         "@phillyhead aw thank you sam phil, i love you ",
         "positive",
         "['aw', 'thank', 'sam', 'phil', 'love']"
        ],
        [
         "49",
         "just got back from swimming at kari's... on another note, i am sick of being frustrated and wish you wouldn't treat me like such a toy. ",
         "negative",
         "['get', 'back', 'swim', 'another', 'note', 'sick', 'frustrate', 'wish', 'treat', 'like', 'toy']"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 400000
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokenized_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Singstar nite last nite....my throat hurts</td>\n",
       "      <td>negative</td>\n",
       "      <td>['singstar', 'nite', 'last', 'nite', 'throat',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Up and ready for work  sad times mmm toast htt...</td>\n",
       "      <td>negative</td>\n",
       "      <td>['ready', 'work', 'sad', 'time', 'mmm', 'toast']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Watching another movie</td>\n",
       "      <td>positive</td>\n",
       "      <td>['watch', 'another', 'movie']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Listening to Ed Schultz interview of Mich. Gov...</td>\n",
       "      <td>negative</td>\n",
       "      <td>['listen', 'ed', 'schultz', 'interview', 'mich...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@timothyh2o last time his bro was making up st...</td>\n",
       "      <td>negative</td>\n",
       "      <td>['last', 'time', 'bro', 'make', 'story', 'coul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399995</th>\n",
       "      <td>watching King of the Hill right now... hilario...</td>\n",
       "      <td>positive</td>\n",
       "      <td>['watch', 'king', 'hill', 'right', 'hilarious']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399996</th>\n",
       "      <td>is excited for the weekend and what's in store..</td>\n",
       "      <td>positive</td>\n",
       "      <td>['excite', 'weekend', 'store']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399997</th>\n",
       "      <td>@i_am_TC k, and you have fun with what you're ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>['k', 'fun']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399998</th>\n",
       "      <td>off for a bit . going to try and rest my poor ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>['bit', 'go', 'try', 'rest', 'poor', 'head']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399999</th>\n",
       "      <td>Look after a picture ! But I can't find it.. d...</td>\n",
       "      <td>negative</td>\n",
       "      <td>['look', 'picture', 'find', 'damn', 'summer', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment  \\\n",
       "0             Singstar nite last nite....my throat hurts   negative   \n",
       "1       Up and ready for work  sad times mmm toast htt...  negative   \n",
       "2                                 Watching another movie   positive   \n",
       "3       Listening to Ed Schultz interview of Mich. Gov...  negative   \n",
       "4       @timothyh2o last time his bro was making up st...  negative   \n",
       "...                                                   ...       ...   \n",
       "399995  watching King of the Hill right now... hilario...  positive   \n",
       "399996  is excited for the weekend and what's in store..   positive   \n",
       "399997  @i_am_TC k, and you have fun with what you're ...  positive   \n",
       "399998  off for a bit . going to try and rest my poor ...  negative   \n",
       "399999  Look after a picture ! But I can't find it.. d...  negative   \n",
       "\n",
       "                                         tokenized_review  \n",
       "0       ['singstar', 'nite', 'last', 'nite', 'throat',...  \n",
       "1        ['ready', 'work', 'sad', 'time', 'mmm', 'toast']  \n",
       "2                           ['watch', 'another', 'movie']  \n",
       "3       ['listen', 'ed', 'schultz', 'interview', 'mich...  \n",
       "4       ['last', 'time', 'bro', 'make', 'story', 'coul...  \n",
       "...                                                   ...  \n",
       "399995    ['watch', 'king', 'hill', 'right', 'hilarious']  \n",
       "399996                     ['excite', 'weekend', 'store']  \n",
       "399997                                       ['k', 'fun']  \n",
       "399998       ['bit', 'go', 'try', 'rest', 'poor', 'head']  \n",
       "399999  ['look', 'picture', 'find', 'damn', 'summer', ...  \n",
       "\n",
       "[400000 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = joblib.load(\"tfidf_vectorizer.pkl\")\n",
    "model_ft = joblib.load(\"fasttext_model.pkl\")\n",
    "best_xgb = joblib.load(\"optimized_tfidf_fasttext_xgboost.pkl\")\n",
    "\n",
    "X_twitter_tfidf = tfidf_vectorizer.transform(df_X_tokenized[\"tokenized_review\"])\n",
    "\n",
    "def get_sentence_vector(tokens):\n",
    "    return np.mean([model_ft.wv[word] for word in tokens if word in model_ft.wv] or [np.zeros(300)], axis=0)\n",
    "\n",
    "X_twitter_ft = np.vstack(df_X_tokenized[\"tokenized_review\"].apply(lambda x: get_sentence_vector(str(x).split())))\n",
    "\n",
    "X_twitter_combined = hstack([X_twitter_tfidf, X_twitter_ft])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_sentiment\n",
      "positive    299073\n",
      "negative    100927\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_X_tokenized[\"prediction\"] = best_xgb.predict(X_twitter_combined)\n",
    "\n",
    "df_X_tokenized[\"predict_sentiment\"] = df_X_tokenized[\"prediction\"].map({0: \"negative\", 1: \"positive\"})\n",
    "\n",
    "print(df_X_tokenized[\"predict_sentiment\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost performance on  Twitter:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.32      0.43    200022\n",
      "    positive       0.55      0.82      0.65    199978\n",
      "\n",
      "    accuracy                           0.57    400000\n",
      "   macro avg       0.59      0.57      0.54    400000\n",
      "weighted avg       0.59      0.57      0.54    400000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"XGBoost performance on  Twitter:\")\n",
    "print(classification_report(df_X_tokenized[\"sentiment\"], df_X_tokenized[\"predict_sentiment\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 160006, number of negative: 159993\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.613604 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 911469\n",
      "[LightGBM] [Info] Number of data points in the train set: 319999, number of used features: 5300\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500020 -> initscore=0.000081\n",
      "[LightGBM] [Info] Start training from score 0.000081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/lightgbm/basic.py:1238: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning(\"Converting data to scipy sparse matrix.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM performance on Twitter:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.27      0.38    200022\n",
      "    positive       0.54      0.86      0.67    199978\n",
      "\n",
      "    accuracy                           0.57    400000\n",
      "   macro avg       0.60      0.57      0.52    400000\n",
      "weighted avg       0.60      0.57      0.52    400000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "model_lgb = LGBMClassifier(n_estimators=500, max_depth=10, learning_rate=0.05)\n",
    "model_lgb.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "df_X_tokenized[\"prediction_lgb\"] = model_lgb.predict(X_twitter_combined)\n",
    "df_X_tokenized[\"predict_sentiment_lgb\"] = df_X_tokenized[\"prediction_lgb\"].map({0: \"negative\", 1: \"positive\"})\n",
    "\n",
    "print(\"LightGBM performance on Twitter:\")\n",
    "print(classification_report(df_X_tokenized[\"sentiment\"], df_X_tokenized[\"predict_sentiment_lgb\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=500)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=500)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=500)\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGR performance on Twitter:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.48      0.53    200022\n",
      "    positive       0.56      0.67      0.61    199978\n",
      "\n",
      "    accuracy                           0.58    400000\n",
      "   macro avg       0.58      0.58      0.57    400000\n",
      "weighted avg       0.58      0.58      0.57    400000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_X_tokenized[\"prediction_lgr\"] = log_reg.predict(X_twitter_combined)\n",
    "df_X_tokenized[\"predict_sentiment_lgr\"] = df_X_tokenized[\"prediction_lgr\"].map({0: \"negative\", 1: \"positive\"})\n",
    "\n",
    "print(\"LGR performance on Twitter:\")\n",
    "print(classification_report(df_X_tokenized[\"sentiment\"], df_X_tokenized[\"predict_sentiment_lgr\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
